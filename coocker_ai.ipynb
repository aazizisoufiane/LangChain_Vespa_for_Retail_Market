{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09ecc495-2e5c-400a-b306-520433a6894d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# \"Vespa.ai and LangChain: Crafting the Ultimate Retail Kitchen Assistant\"\n",
    "\n",
    "\n",
    "![Author](https://img.shields.io/badge/Author-Soufiane%20AAZIZI-brightgreen)\n",
    "[![Medium](https://img.shields.io/badge/Medium-Follow%20Me-blue)](https://medium.com/@aazizi.soufiane)\n",
    "[![GitHub](https://img.shields.io/badge/GitHub-Follow%20Me-lightgrey)](https://github.com/aazizisoufiane)\n",
    "[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect%20with%20Me-informational)](https://www.linkedin.com/in/soufiane-aazizi-phd-a502829/)\n",
    "\n",
    "-----\n",
    "\n",
    "The primary objective of this notebook is to interact with a Language Model (LLM) to inquire about a recipe. The LLM will respond with the recipe's ingredients and cooking instructions. However, the key highlight is that it will generate recommendations for each ingredient from our store using Vespa.ai, a retrieval system. This means that for each ingredient, it will suggest related products or items that you might want to consider when preparing the recipe.\n",
    "\n",
    "**Example:**\n",
    "Suppose you ask the LLM for a recipe for \"Spaghetti Bolognese.\" The LLM will not only provide you with the list of ingredients and cooking instructions but also suggest products like pasta, ground beef, tomatoes, and spices that you may need to purchase for making the dish. This recommendation is based on the available products in our store, enhancing your cooking experience.\n",
    "\n",
    "# [Build and Deploy Vespa](#build-deploy-vespa)\n",
    "## [Application package](#application-package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "45cc3316-58c0-48ed-a272-fca8af1fdcb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d653f4e9-f3b5-4667-8041-27c5289ab515",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1a04457a-c475-41ed-9a5a-6846cea2c774",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0b66863e-806e-4197-a7de-2de2ab264408",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "application_name = \"productsContent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9f01687b-b30a-4949-a867-fd64577494cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dataframe_to_vespa_format(input_df, output_file, application_name):\n",
    "    # Create and open the output JSONL file for writing\n",
    "    with open(output_file, \"w\") as jsonl_file:\n",
    "        # Iterate through each row in the DataFrame\n",
    "        for index, row in input_df.iterrows():\n",
    "            # Extract relevant data from the DataFrame\n",
    "            id_value = row[\"id\"]\n",
    "            # price_value = row[\"Price\"].replace(\n",
    "            #     \",\", \".\"\n",
    "            # )  # Replace comma with dot for proper float representation\n",
    "            price_value = str(row[\"Price\"])\n",
    "            body_value = (\n",
    "                \"\\nName: \"\n",
    "                + row[\"title\"]\n",
    "                + \" \\nDescription: \"\n",
    "                + row[\"description\"]\n",
    "                + \" \\nPrice: \"\n",
    "                + price_value\n",
    "            )\n",
    "            # Extract the second-to-last word from the 'body' column\n",
    "\n",
    "            # Create the JSON structure\n",
    "            json_record = {\n",
    "                \"put\": f\"id:{application_name}:{application_name}::{id_value}\",\n",
    "                \"fields\": {\n",
    "                    \"Price\": price_value,\n",
    "                    \"title\": row[\"title\"],\n",
    "                    \"description\": row[\"description\"],\n",
    "                    \"body\": body_value,\n",
    "                },\n",
    "            }\n",
    "\n",
    "            # Write the JSON record to the JSONL file\n",
    "            jsonl_file.write(json.dumps(json_record) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5093aaa3-f5ce-4224-b3a7-a1d2cb4bd2e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "products = pd.read_csv(\"retail_product.csv\")\n",
    "dataframe_to_vespa_format(products, \"produits.jsonl\", application_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f77ce75-3793-49b0-b947-fe2fef014312",
   "metadata": {},
   "source": [
    "# Build and Deploy Vespa <a class=\"anchor\" id=\"build-deploy-vespa\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298a5bbd-c711-4a55-b92e-177a6708ad62",
   "metadata": {},
   "source": [
    "In this section, we need to build a Vespa application. Before that, we start by installing Docker locally. You can install [Docker Desktop for Mac/Windows](https://docs.docker.com/engine/install/).\n",
    "For deepdive into vespa [Vespa](https://docs.vespa.ai/en/getting-started.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18f15ce-e1a4-4efc-bf9a-436abdf85a49",
   "metadata": {},
   "source": [
    "### Export the model to ONNX format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d60dc3-1aa4-4b7f-966c-d74e80c5dbb9",
   "metadata": {},
   "source": [
    "Vespa offers flexibility in using various embedding methods, including the [ONNX format](https://docs.vespa.ai/en/embedding.html#onnx-export), which is compatible with both the Bert embedder and the Huggingface embedder. In this case, we've chosen to use the [Huggingface embedder](https://docs.vespa.ai/en/embedding.html#huggingface-embedder) with the [all-MiniLM-L6-v2 model](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2).\n",
    "\n",
    "To set up the embedding, you can follow these steps:\n",
    "\n",
    "1. Export the ONNX model:\n",
    "\n",
    "    ```bash\n",
    "    sudo python export_model_from_hf.py --hf_model sentence-transformers/all-MiniLM-L6-v2 --output_dir all-MiniLM-L6-v2\n",
    "    ```\n",
    "\n",
    "2. Debug ONNX models using Vespa's built-in tools. Refer to the [Vespa documentation](https://docs.vespa.ai/en/embedding.html#onnx-export) for more details on this step.\n",
    "\n",
    "    ```bash\n",
    "    docker run -v `pwd`:/w \\\n",
    "      --entrypoint /opt/vespa/bin/vespa-analyze-onnx-model \\\n",
    "      vespaengine/vespa \\\n",
    "      /w/sentence-transformers-all-MiniLM-L6-v2.onnx\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee81f7da-142d-4f9b-8c19-d8054178e9d7",
   "metadata": {},
   "source": [
    "### Application package <a class=\"anchor\" id=\"application-package\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e6b3bd7e-11df-4204-8777-23d0326ff154",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vespa.package import ApplicationPackage\n",
    "from vespa.package import *\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd6e2f6-82ee-48de-9f05-4ebe863060c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "Create an application package from scratch. it will create all  Vespa configuration files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "655c3827-0a13-470f-8d56-c8418324c965",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "app_package = ApplicationPackage(name=application_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78ebd50-c6fc-4068-bf2f-59c23c98e99f",
   "metadata": {},
   "source": [
    "After generating and debugging our ONNX model, we can integrate it into our Vespa application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f78007c1-1605-431b-914e-86b401ab91ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "app_package = ApplicationPackage(\n",
    "    name=application_name,\n",
    "    components=[\n",
    "        Component(\n",
    "            # id=\"e5-small-q\",\n",
    "            id=\"e5\",\n",
    "            type=\"hugging-face-embedder\",\n",
    "            parameters=[\n",
    "                Parameter(\n",
    "                    \"transformer-model\",\n",
    "                    {\n",
    "                        \"path\": \"model/all-MiniLM-L6-v2/sentence-transformers-all-MiniLM-L6-v2.onnx\"\n",
    "                    },\n",
    "                ),\n",
    "                Parameter(\n",
    "                    \"tokenizer-model\", {\"path\": \"model/all-MiniLM-L6-v2/tokenizer.json\"}\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eec2b2-09f6-46a5-ba56-33a2b7a87737",
   "metadata": {},
   "source": [
    "In our JSON file, we've defined specific keys that we will use to **populate Vespa fields** for our Vespa application. \n",
    "\n",
    "Before we embark on this journey, it's crucial to grasp the significance of the **BM25 ranking function**â€”an integral part of our Vespa application. \n",
    "\n",
    "**BM25** is more than just a ranking function; it's the magic wand of information retrieval. It meticulously gauges the relevance of documents to search queries by delving into factors like term frequency, inverse document frequency, and document length. \n",
    "\n",
    "\n",
    "Additionally, we employ the power of **indexing**. These indexes are the treasure maps of Vespa, created for specific fields. They're the superhighways of data retrieval, ensuring swift and efficient searches. \n",
    "\n",
    "For a deeper dive into indexing, consult the [Vespa documentation](https://docs.vespa.ai/en/reference/schema-reference.html#indexing), where you'll find the keys to unlocking even more potential.\n",
    "\n",
    "**HNSW**, short for Hierarchical Navigable Small World, is a data structure and algorithm employed in approximate nearest neighbor search. It excels at efficiently locating data points in high-dimensional spaces by constructing a hierarchical graph structure, facilitating rapid and scalable similarity searches. HNSW is commonly utilized in machine learning and data retrieval applications where the speedy identification of similar data points is essential, such as recommendation systems and image recognition.\n",
    "\n",
    "**Angular distance** is a measure of the shortest separation or difference between two points, typically in the context of spherical coordinates or geographic locations. It is commonly used to calculate the shortest path or great-circle distance between two points on the surface of a sphere, such as measuring the distance between two locations on the Earth's surface. Angular distance is typically expressed in degrees, radians, or other angular units, taking into account the curvature of the surface, and is essential in geographic applications for determining the shortest route or distance between two points on a spherical object like the Earth.\n",
    "\n",
    "**tensor**: This indicates that the tensor contains floating-point values. It's a way of specifying the data type of the elements within the tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dea4c0c7-9d47-476d-b32b-c5ffd16c516b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "app_package.schema.add_fields(\n",
    "    Field(name=\"id\", type=\"int\", indexing=[\"attribute\", \"summary\"]),\n",
    "    Field(\n",
    "        name=\"body\",\n",
    "        type=\"string\",\n",
    "        indexing=[\"index\", \"summary\"],\n",
    "        index=\"enable-bm25\",\n",
    "        bolding=True,\n",
    "    ),\n",
    "    Field(\n",
    "        name=\"title\",\n",
    "        type=\"string\",\n",
    "        indexing=[\"index\", \"summary\"],\n",
    "        index=\"enable-bm25\",\n",
    "        bolding=True,\n",
    "    ),\n",
    "    Field(\n",
    "        name=\"description\",\n",
    "        type=\"string\",\n",
    "        indexing=[\"index\", \"summary\"],\n",
    "        index=\"enable-bm25\",\n",
    "        bolding=True,\n",
    "    ),\n",
    "    Field(name=\"Price\", type=\"string\", indexing=[\"attribute\", \"summary\"]),\n",
    "    Field(\n",
    "        name=\"title_embeddings\",\n",
    "        type=\"tensor<float>(x[384])\",\n",
    "        indexing=[\"input title\", \"embed\", \"index\", \"attribute\"],\n",
    "        ann=HNSW(distance_metric=\"angular\"),\n",
    "        is_document_field=False,\n",
    "    ),\n",
    "    Field(\n",
    "        name=\"description_embeddings\",\n",
    "        type=\"tensor<float>(x[384])\",\n",
    "        indexing=[\"input description\", \"embed\", \"index\", \"attribute\"],\n",
    "        ann=HNSW(distance_metric=\"angular\"),\n",
    "        is_document_field=False,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6489a47e-9210-483c-a336-19d3e13f6c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_package.schema.add_field_set(\n",
    "    FieldSet(name=\"default\", fields=[\"title\", \"description\", \"body\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320b3c1b-3f2b-4317-a7e9-95b4c2c21bdb",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "We have defined a hybrid rank profile that takes into account both semantic search and BM25, combining them to determine the relevance of search results.\n",
    "\n",
    "**First Phase Formula**\n",
    "\n",
    "In the first phase of ranking, the formula is as follows:\n",
    "\n",
    "```markdown\n",
    "first_phase = 100 * closeness(title_embeddings) + 50 * closeness(description_embeddings) + 0.5 * bm25(body)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c6733b7a-9d7d-45bb-81db-3ef24e21d596",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "app_package.schema.add_rank_profile(\n",
    "    RankProfile(name=\"bm25\", first_phase=\"bm25(title) + 0.5 * bm25(description)\")\n",
    ")\n",
    "\n",
    "\n",
    "app_package.schema.add_rank_profile(\n",
    "    RankProfile(\n",
    "        name=\"hybrid\",\n",
    "        inputs=[(\"query(q)\", \"tensor<float>(x[384])\")],\n",
    "        inherits=\"default\",\n",
    "        first_phase=\"100*closeness(title_embeddings) + 50*closeness(description_embeddings)  + 0.5*bm25(body)\",\n",
    "        match_features=[\n",
    "            \"closeness(title_embeddings) \\\n",
    "        closeness(title_embeddings)  \\\n",
    "        bm25(body)\"\n",
    "        ],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f88f27-3cba-4f4e-82cf-b296d659a789",
   "metadata": {},
   "source": [
    "We export the application package to the disk before deployment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2c966cfd-52a7-483b-8578-8aaa62cd155b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "app_package.schema.add_document_summary(\n",
    "    DocumentSummary(\n",
    "        name=\"all\",\n",
    "        summary_fields=[\n",
    "            Summary(\"id\", \"int\"),\n",
    "            Summary(\"title\", \"string\"),\n",
    "            Summary(\"description\", \"string\"),\n",
    "            Summary(\"Price\", \"string\"),\n",
    "        ],\n",
    "    )\n",
    ")\n",
    "\n",
    "Path(\"pkg\").mkdir(parents=True, exist_ok=True)\n",
    "app_package.to_files(\"pkg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6307228-4c74-4825-bbcf-6166baff9f9b",
   "metadata": {},
   "source": [
    "Deploy `app_package` on the local machine using Docker, without leaving the notebook, by creating an instance of `VespaDocker`. You can use this command line:\n",
    "\n",
    "```python\n",
    "vespa_docker = vespa_docker.from_container_name_or_id(application_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "67c370ae-6d34-44b8-8139-133770608593",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vespa.deployment import Vespa\n",
    "\n",
    "app = Vespa(\"http://localhost:8080/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be2590ab-3477-4ced-99ff-19300a076eed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for configuration server, 0/300 seconds...\n",
      "Waiting for configuration server, 5/300 seconds...\n",
      "Waiting for application status, 0/300 seconds...\n",
      "Waiting for application status, 5/300 seconds...\n",
      "Finished deployment.\n"
     ]
    }
   ],
   "source": [
    "from vespa.deployment import VespaDocker\n",
    "\n",
    "vespa_docker = VespaDocker(port=8080)\n",
    "app = vespa_docker.deploy_from_disk(\n",
    "    application_name=application_name, application_root=\"pkg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1e2644-7f91-4958-b9c5-36dac1b0acfb",
   "metadata": {},
   "source": [
    "Now that we've deployed our Vespa application successfully, we need to install [VESPA CLI](https://docs.vespa.ai/en/vespa-cli.html) and use it to feed our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84946a9d-01aa-4e66-886f-2004813a7f2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use endpoints on localhost\n",
    "! vespa config set target local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f34e21c-89bf-4058-b7de-8fb9ff2bcc22",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"feeder.seconds\": 173.721,\n",
      "  \"feeder.ok.count\": 20262,\n",
      "  \"feeder.ok.rate\": 116.635,\n",
      "  \"feeder.error.count\": 0,\n",
      "  \"feeder.inflight.count\": 0,\n",
      "  \"http.request.count\": 20262,\n",
      "  \"http.request.bytes\": 4470241,\n",
      "  \"http.request.MBps\": 0.026,\n",
      "  \"http.exception.count\": 0,\n",
      "  \"http.response.count\": 20262,\n",
      "  \"http.response.bytes\": 2368696,\n",
      "  \"http.response.MBps\": 0.014,\n",
      "  \"http.response.error.count\": 0,\n",
      "  \"http.response.latency.millis.min\": 248,\n",
      "  \"http.response.latency.millis.avg\": 9068,\n",
      "  \"http.response.latency.millis.max\": 11715,\n",
      "  \"http.response.code.counts\": {\n",
      "    \"200\": 20262\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display a periodic summary every 3 seconds while feeding:\n",
    "! vespa  feed --progress=3 produits.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b11a19-f63e-4ba7-9763-de0c76e7dd16",
   "metadata": {},
   "source": [
    "Check the number of feeded documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7e3c6d4f-40e7-47ea-bac8-586d59a314a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20262"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.query(body={\"yql\": \"select * from sources * where true\"}).number_documents_indexed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26ab0b3-3761-4e80-845d-bf20ab5771f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "Make a simple query to test our application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "18b04a1b-6f8e-47a9-bfb9-2dc17343fc58",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'id:productsContent:productsContent::13714',\n",
       "  'relevance': 74.40122045460956,\n",
       "  'source': 'productsContent_content',\n",
       "  'fields': {'matchfeatures': {'bm25(body)': 0.0,\n",
       "    'closeness(title_embeddings)': 0.5283060204679746},\n",
       "   'sddocname': 'productsContent',\n",
       "   'description': '1.5 l can',\n",
       "   'body': '\\nName: extra organic virgin olive oil \\nDescription: 1.5 l can \\nPrice: 27.9195',\n",
       "   'title': 'extra organic virgin olive oil',\n",
       "   'documentid': 'id:productsContent:productsContent::13714',\n",
       "   'Price': '27.9195'}},\n",
       " {'id': 'id:productsContent:productsContent::2171',\n",
       "  'relevance': 66.18247444140717,\n",
       "  'source': 'productsContent_content',\n",
       "  'fields': {'matchfeatures': {'bm25(body)': 0.0,\n",
       "    'closeness(title_embeddings)': 0.43010505946507765},\n",
       "   'sddocname': 'productsContent',\n",
       "   'description': '130 g cheese',\n",
       "   'body': '\\nName: goat cheese 1/2 sec \\nDescription: 130 g cheese \\nPrice: 2.52',\n",
       "   'title': 'goat cheese 1/2 sec',\n",
       "   'documentid': 'id:productsContent:productsContent::2171',\n",
       "   'Price': '2.52'}}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword = \"olive  1 tablespoon\"\n",
    "\n",
    "result = app.query(\n",
    "    body={\n",
    "        \"yql\": \"select * from productsContent_content where userQuery() \\\n",
    "        or ({targetHits:1}nearestNeighbor(title_embeddings,q)) \\\n",
    "        or ({targetHits:1}nearestNeighbor(description_embeddings,q)) \\\n",
    "        \",\n",
    "        \"input.query(q)\": f\"embed({keyword})\",\n",
    "        \"query\": f\"{keyword}\",\n",
    "        \"ranking.profile\": \"hybrid\",\n",
    "        \"bolding\": False,\n",
    "        \"hits\": 5,\n",
    "    }\n",
    ")\n",
    "result.hits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c0ebc2-39c9-4d0e-bc37-a7b5f0f4a466",
   "metadata": {},
   "source": [
    "# LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f84cfaf4-194a-4cf2-ab18-90d201045931",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.agents import AgentType\n",
    "from langchain.retrievers.vespa_retriever import VespaRetriever\n",
    "from vespa.application import Vespa\n",
    "\n",
    "# Load environment variables from the local .env file, including OPENAI_API_KEY\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "MAX_HISTORY_LENGTH = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63ab6a0-cf9f-44dc-9d31-bc60727ac1eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Config VespaRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "212e828d-0820-4aea-8b3f-92d708c41b7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "app = Vespa(url=\"http://localhost\", port=8080)\n",
    "VespaRetriever.update_forward_refs(Vespa=Vespa)  # We need this line on Jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdf8ffc-80d9-40e8-a234-c930062ba43d",
   "metadata": {},
   "source": [
    "### Import LangChain tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a801187-fb8d-444a-bb49-be9d3d95f4d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "from typing import Type, List, Union\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.output_parsers import PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78be833c-8c0e-4a6f-b4f9-f19ff9ff0e58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up our language model (LLM) with the specified parameters\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0613\", temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e084128-a8f0-4d12-ae2d-a9cc8765c320",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IngredientItem(BaseModel):\n",
    "    name: str\n",
    "    quantity: str\n",
    "    \n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    ingredients: List[IngredientItem]\n",
    "    instruction: List\n",
    "\n",
    "\n",
    "class Recommendation(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "    price: Union[float, None]\n",
    "    \n",
    "    @validator(\"price\", pre=True, always=True)\n",
    "    def handle_null_price(cls, value):\n",
    "        # Convert \"null\" to None or set a default value if needed\n",
    "        if value is None or value == \"null\":\n",
    "            return None  # Change \"null\" to None\n",
    "        try:\n",
    "            return float(value)\n",
    "        except (TypeError, ValueError):\n",
    "            return None  # Handle invalid values gracefully\n",
    "\n",
    "\n",
    "\n",
    "class Recs(BaseModel):\n",
    "    recommendations: List[Recommendation] = Field(description=\"List of recommendations\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6cb0dc8-0469-4019-a322-4d9fc39ad62c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKBOLDBLUE = '\\033[1;34m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    OKYELLOW = '\\033[33m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "add64fac-2d80-4817-9635-19592dda4bb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an instance of PydanticOutputParser with the 'Recs' Pydantic model\n",
    "parser_extraction = PydanticOutputParser(pydantic_object=Recs)\n",
    "\n",
    "# Create another instance of PydanticOutputParser with the 'Recipe' Pydantic model\n",
    "parser_ingredient = PydanticOutputParser(pydantic_object=Recipe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c1c893-c9e4-460b-b924-506aad57c3cb",
   "metadata": {},
   "source": [
    "# Function Explanation: build_chain()\n",
    "\n",
    "The function `build_chain()` is responsible for constructing a processing chain designed to list the ingredients required for a recipe. Below is an explanation of the function's purpose and its inner workings:\n",
    "\n",
    "**Function Purpose:**\n",
    "The primary objective of this function is to create a processing chain for culinary tasks. Specifically, it aims to provide a list of ingredients needed to prepare a given recipe. The function returns an `LLMChain` object, which represents a chain of processing steps for handling recipe-related information.\n",
    "\n",
    "**Function Details:**\n",
    "\n",
    "- **Template Definition:** Inside the function, there's a multi-line string named `recipe_ingredients_template`. This string serves as a template for creating a message prompt that will be presented to the language model. It outlines the mission for the culinary expert using placeholders like `{recipe}` and `{format_instructions}`.\n",
    "\n",
    "- **Format Instructions:** The function retrieves format instructions from the `parser_ingredient` object by calling `parser_ingredient.get_format_instructions()`. These instructions are used within the message prompt template.\n",
    "\n",
    "- **Human Message Prompt Template:** The function defines a `human_message_prompt` using the `HumanMessagePromptTemplate`. It specifies the message prompt template based on `recipe_ingredients_template`. It expects an input variable named \"recipe\" and provides partial variables, including \"format_instructions.\"\n",
    "\n",
    "- **Chat Prompt Template:** A `chat_prompt_template` is created using the `ChatPromptTemplate` and is based on the `human_message_prompt`.\n",
    "\n",
    "- **LLMChain Creation:** The function then constructs an `LLMChain` named `llm_chain`. This chain utilizes a language model (`llm`) and the chat prompt template.\n",
    "\n",
    "- **Return:** Finally, the function returns the `LLMChain` object `llm_chain` as its result.\n",
    "\n",
    "In summary, this function sets up a chain of processing steps for generating precise ingredient lists for various recipes. It utilizes a language model, agent, and message prompts to encapsulate the entire information extraction process and returns the processing chain for further use in culinary-related tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14fb019e-9b7d-45f0-bb89-4aaf9892c520",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define a docstring for the function 'build_chain'\n",
    "def build_chain():\n",
    "    \"\"\"\n",
    "    Build a chain for listing ingredients of a recipe.\n",
    "\n",
    "    Returns:\n",
    "        LLMChain: A chain for processing recipe-related information.\n",
    "    \"\"\"\n",
    "    recipe_ingredients_template = \"\"\" You are a culinary expert known for your meticulous recipe analysis.\n",
    "    Your task is to list all the ingredients required for a specific recipe. \n",
    "    You have a vast knowledge of recipes from around the world and can provide precise ingredient lists for various dishes.\n",
    "\n",
    "    Here's your challenge:\n",
    "    Given the name of a recipe, list all the ingredients needed to prepare that dish. Include exact quantities and instruction.\n",
    "\n",
    "    Recipe Name: {recipe}\n",
    "\n",
    "    {format_instructions}\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve format instructions from the PydanticOutputParser\n",
    "    format_instructions = parser_ingredient.get_format_instructions()\n",
    "\n",
    "    # Define a human message prompt template\n",
    "    human_message_prompt = HumanMessagePromptTemplate(\n",
    "        prompt=PromptTemplate(\n",
    "            template=recipe_ingredients_template,\n",
    "            input_variables=[\"recipe\"],\n",
    "            partial_variables={\"format_instructions\": format_instructions},\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Create a chat prompt template\n",
    "    chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "\n",
    "    # Create an LLMChain with the language model\n",
    "    return LLMChain(llm=llm, prompt=chat_prompt_template, verbose=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0418564-5174-49c9-ae2b-665717fecc31",
   "metadata": {},
   "source": [
    "**Note**: We can consider other templates and use RouterChain by adapting our previous example. Here are some additional templates that we can add or replace with the previous one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fee5a8e-05f4-4cf5-bada-aeacca295361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "healthy_recipe_template = \"\"\"You are a health-conscious culinary expert known for crafting nutritious and delicious recipes. \n",
    "Your mission is to provide a list of ingredients and instructions for a healthy and balanced meal. Whether it's a salad, smoothie,\n",
    "or low-calorie dish, you're here to guide users toward healthier choices.\n",
    "\n",
    "Recipe Name: {3recipe}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "vegetarian_recipe_template = \"\"\"As a vegetarian culinary expert, you specialize in meat-free recipes that are both satisfying and delicious. \n",
    "Your task is to compile a list of ingredients and detailed instructions for a vegetarian dish, ensuring it's both flavorful and satisfying.\n",
    "\n",
    "Recipe Name: {recipe}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "vegan_recipe_template = \"\"\"You are a dedicated vegan chef, passionate about creating plant-based recipes. \n",
    "Your challenge is to provide a comprehensive list of ingredients and step-by-step instructions for a vegan-friendly dish. \n",
    "Your goal is to help users enjoy a cruelty-free and environmentally conscious meal.\n",
    "\n",
    "Recipe Name: {recipe}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "gluten_free_recipe_template = \"\"\"As a gluten-free cooking expert, you excel in crafting recipes suitable for individuals with gluten sensitivities or allergies. \n",
    "Your mission is to outline the ingredients and preparation steps for a gluten-free dish that is safe and delicious for those with specific dietary \n",
    "requirements.\n",
    "\n",
    "Recipe Name: {recipe}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "low_carb_recipe_template = \"\"\"You specialize in low-carb cooking, helping individuals maintain a reduced carbohydrate intake. Your task is to present a \n",
    "list of ingredients and cooking instructions for a low-carb recipe that is both satisfying and suitable for those following a low-carb lifestyle.\n",
    "\n",
    "Recipe Name: {recipe}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d343991-cd9e-44a7-9e7f-e0ca3525b15d",
   "metadata": {},
   "source": [
    "### Overall Purpose\n",
    "\n",
    "**Objective**: The primary purpose of the `build_extraction_chain()` function is to establish a processing chain tailored to the task of identifying the most suitable ingredients available in our store. This process aims to construct a recommendation engine that provides recommendations for each ingredient based on its availability and suitability for various recipes.\n",
    "### Key Components\n",
    "\n",
    "1. **Search Function**: The notebook includes a `search` function that leverages Vespa, a search engine, to retrieve relevant product information based on user queries.\n",
    "\n",
    "2. **Ingredient Price Tool**: A custom class named `IngredientPriceTool` is defined to provide product suggestions and identify optimal options with the lowest prices based on ingredient names and quantities.\n",
    "\n",
    "3. **Agent Creation**: The `build_agent` function is responsible for creating a culinary agent, equipped with tools like the `IngredientPriceTool`, to manage culinary-related tasks.\n",
    "\n",
    "4. **Extraction Chain**: The `build_extraction_chain` function constructs an extraction chain designed for culinary tasks. It combines a language model and the culinary agent to extract various types of information, including recommendations, ingredient lists, and cooking instructions.\n",
    "\n",
    "### Workflow\n",
    "\n",
    "1. Users interact with the notebook by inputting queries related to recipes and culinary tasks.\n",
    "\n",
    "2. The `search` function is employed to process user queries and retrieve relevant product information using Vespa.\n",
    "\n",
    "3. A culinary agent, created using the `build_agent` function, assists in providing ingredient suggestions and handling culinary tasks.\n",
    "\n",
    "4. The `build_extraction_chain` function manages the extraction of culinary information by utilizing the language model and culinary agent.\n",
    "\n",
    "5. Users receive responses that include ingredient lists, product recommendations, and cooking instructions based on their queries.\n",
    "\n",
    "**Note:** As we currently cannot use our [VespaRetriever](https://python.langchain.com/docs/integrations/retrievers/vespa) in its current form since it only overrides the query parameter, the temporary solution is to initialize a new retriever for every query. This will be the approach until it is fixed by the Langchain/Vespa teams. To streamline this process, we will create an agent that will handle the search operations on our behalf.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9aa1ba-7f58-4751-94b3-f9f4f15d47cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8b8b064-f82d-4988-a017-00c548dc189b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a docstring for the function 'search'\n",
    "def search(query, hits=100):\n",
    "    \"\"\"\n",
    "    Perform a search query using Vespa.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query.\n",
    "        hits (int): The number of search results to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of relevant documents.\n",
    "    \"\"\"\n",
    "    yql = {\n",
    "        \"yql\": \"select * from productsContent_content where userQuery() \\\n",
    "        or ({targetHits:1}nearestNeighbor(title_embeddings,q)) \\\n",
    "        or ({targetHits:1}nearestNeighbor(description_embeddings,q)) \\\n",
    "        \",\n",
    "        \"input.query(q)\": f\"embed({query})\",\n",
    "        \"query\": f\"{query}\",\n",
    "        \"ranking.profile\": \"hybrid\",\n",
    "        \"bolding\": False,\n",
    "        \"hits\": hits,\n",
    "    }\n",
    "\n",
    "    # Create a Vespa retriever\n",
    "    retriever = VespaRetriever(\n",
    "        app=app,\n",
    "        body=yql,\n",
    "        content_field=\"body\",\n",
    "        metadata_fields=[\"Price\"],\n",
    "        # metadata={\"body\": str},\n",
    "    )\n",
    "\n",
    "    # Get relevant documents based on the query\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "    return [d.page_content for d in docs]\n",
    "\n",
    "class IngredientInput(BaseModel):\n",
    "    \"\"\"Inputs for IngredientTool\"\"\"\n",
    "\n",
    "    ingredient_name: str = Field(description=\"Ingredient name for recipe\")\n",
    "    quantity: str = Field(description=\"quantity of ingredient for recipe\")\n",
    "\n",
    "\n",
    "class IngredientPriceTool(BaseTool):\n",
    "    name = \"IngredientTool\"\n",
    "    description = \"\"\" Please provide a list of product suggestions from the catalog based on the ingredients listed in the line. \n",
    "    Ensure that each product has the optimal quantity and the lowest price. If no exact match is found for an ingredient, please use 'MISSING'. \n",
    "    For multiple ingredients, search for the best product option for each individual ingredient.\n",
    "\n",
    "    Here is the output schema:\n",
    "    ```\n",
    "    {\"properties\": {\"ingredient\": \n",
    "        {\n",
    "            \"title\": \"Ingredient\", \"description\": \"Provide suggestions\", \"type\": \"array\", \"items\": {}}, \n",
    "            \"required\": [\"ingredient\"]\n",
    "            }\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    \"\"\"\n",
    "    # provide answer as: \"\\nProduct:   \\Quantity:    \\Instruction:\n",
    "\n",
    "    args_schema: Type[BaseModel] = IngredientInput\n",
    "\n",
    "    def _run(self, ingredient_name: str, quantity: str):\n",
    "        price_response = search(ingredient_name + quantity)\n",
    "        return price_response\n",
    "\n",
    "    def _arun(self, ticker: str):\n",
    "        raise NotImplementedError(\"search does not support async\")   \n",
    "\n",
    "def build_agent():\n",
    "    \"\"\"\n",
    "    Build a culinary agent.\n",
    "\n",
    "    Returns:\n",
    "        Agent: A culinary agent with specified tools and settings.\n",
    "    \"\"\"\n",
    "    tools = [IngredientPriceTool()]\n",
    "\n",
    "    # Initialize the agent with tools and settings\n",
    "    agent = initialize_agent(\n",
    "        tools,\n",
    "        llm,\n",
    "        agent=AgentType.OPENAI_MULTI_FUNCTIONS,\n",
    "        verbose=False,\n",
    "    )\n",
    "    return agent\n",
    "\n",
    "def build_extraction_chain():\n",
    "    \"\"\"\n",
    "    Build an extraction chain for culinary tasks.\n",
    "\n",
    "    Returns:\n",
    "        SimpleSequentialChain: A chain of processing steps for extracting culinary information.\n",
    "    \"\"\"\n",
    "    extract_ingredients_template = \"\"\"As a culinary expert tasked with extracting recommendations from the text, your mission is as follows:\n",
    "\n",
    "    Recipe Name: {text}\n",
    "\n",
    "    {format_instructions}\n",
    "    \"\"\"\n",
    "\n",
    "    # Define a human message prompt template\n",
    "    human_message_prompt = HumanMessagePromptTemplate(\n",
    "        prompt=PromptTemplate(\n",
    "            template=extract_ingredients_template,\n",
    "            input_variables=[\"text\"],\n",
    "            partial_variables={\n",
    "                \"format_instructions\": parser_extraction.get_format_instructions()\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Create a chat prompt template\n",
    "    chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "\n",
    "    # Create an extraction chain with the language model\n",
    "    extract_recs_chain = LLMChain(llm=llm, prompt=chat_prompt_template, verbose=False)\n",
    "\n",
    "    # Build the agent and create a simple sequential chain\n",
    "    _agent = build_agent()\n",
    "    ss = SimpleSequentialChain(chains=[_agent, extract_recs_chain], verbose=False)\n",
    "    return ss\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2c51262-7f91-4df6-a61b-470417879dab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_ingredients_with_color(ingredients):\n",
    "    \"\"\"\n",
    "    Print a list of ingredients with colored formatting.\n",
    "\n",
    "    Args:\n",
    "        ingredients (list): A list of ingredient objects.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    for ingredient in ingredients:\n",
    "        formatted_ingredient = f\"{bcolors.OKBLUE}{ingredient.name} - {ingredient.quantity}{bcolors.ENDC}\"\n",
    "        print(formatted_ingredient)\n",
    "\n",
    "def print_recommendations_with_color(search_query, recommendations):\n",
    "    \"\"\"\n",
    "    Print search recommendations with colored formatting.\n",
    "\n",
    "    Args:\n",
    "        search_query (str): The search query.\n",
    "        recommendations (list): A list of recommendation objects.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Print the search query in bold and blue\n",
    "    print(f\"{bcolors.OKBOLDBLUE}{search_query}{bcolors.ENDC}\")  # Bold blue text\n",
    "    \n",
    "    # Iterate through recommendations and print them in yellow\n",
    "    for recommendation in recommendations.recommendations:\n",
    "        name = recommendation.name\n",
    "        description = recommendation.description\n",
    "        price = recommendation.price\n",
    "        print(f\"{bcolors.OKYELLOW}{name} - Description: {description} - Price: {price} {bcolors.ENDC}\")  # Yellow text\n",
    "    \n",
    "    # Reset text formatting\n",
    "    print(bcolors.ENDC)  # Reset text formatting to default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee24df6-34ef-4821-aec6-ae1099936113",
   "metadata": {},
   "source": [
    "### Recipe Recommendation and Ingredient Listing\n",
    "\n",
    "This script is designed to provide recipe recommendations and list ingredients based on user input. It utilizes a conversational AI model and a data retrieval system to create an interactive culinary experience. Here's how it works:\n",
    "\n",
    "- The script begins by initializing a chain for generating ingredients and recommendations.\n",
    "- Users are welcomed with a message prompting them to ask for a recipe or start a new search.\n",
    "\n",
    "#### Input and Processing\n",
    "\n",
    "- Users can input a recipe request or start a new search by typing their query.\n",
    "- The script then runs the ingredient chain to retrieve a list of ingredients for the requested recipe.\n",
    "- The retrieved ingredients are displayed to the user.\n",
    "\n",
    "#### Recommendation Engine\n",
    "\n",
    "- Next, the script builds an extraction chain to gather recommendations for each ingredient from a store.\n",
    "- It provides recommendations for available products based on the ingredients listed.\n",
    "- These recommendations are displayed to the user.\n",
    "\n",
    "#### Recipe Instructions\n",
    "\n",
    "- In addition to ingredients and recommendations, the script also provides recipe instructions.\n",
    "- The user receives step-by-step instructions for preparing the requested dish.\n",
    "\n",
    "#### Interaction and Exit\n",
    "\n",
    "- After displaying the ingredients, recommendations, and instructions, the script prompts the user for the next action.\n",
    "- Users can ask for another recipe, start a new search, or exit by using the \"CTRL-D\" shortcut (EOF).\n",
    "\n",
    "This script combines the power of conversational AI, data retrieval, and culinary expertise to enhance the user's cooking experience. It's a handy tool for finding recipes and making informed ingredient choices. Enjoy exploring new dishes and flavors!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "969991ff-e3b9-4589-af5f-31df809532d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96mAsk for any recipe, start a new search.\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Hamburger\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mINGREDIENTS \n",
      "\u001b[0m\n",
      "\u001b[94mground beef - 1 pound\u001b[0m\n",
      "\u001b[94monion - 1 small, finely chopped\u001b[0m\n",
      "\u001b[94mgarlic - 2 cloves, minced\u001b[0m\n",
      "\u001b[94msalt - 1/2 teaspoon\u001b[0m\n",
      "\u001b[94mblack pepper - 1/4 teaspoon\u001b[0m\n",
      "\u001b[94mhamburger buns - 4\u001b[0m\n",
      "\u001b[94mcheese - 4 slices\u001b[0m\n",
      "\u001b[94mlettuce - 4 leaves\u001b[0m\n",
      "\u001b[94mtomato - 4 slices\u001b[0m\n",
      "\u001b[94mpickles - 4 slices\u001b[0m\n",
      "\u001b[94mketchup - to taste\u001b[0m\n",
      "\u001b[94mmustard - to taste\u001b[0m\n",
      "\u001b[1;34m\n",
      "\n",
      " RECOMMENDATIONS \n",
      "\u001b[0m\n",
      "\u001b[1;34mground beef - 1 pound\u001b[0m\n",
      "\u001b[33mGround beef brochettes nature socopa - Description: 4 - 400g tray - Price: 5.45 \u001b[0m\n",
      "\u001b[33mBrie good mayennay - Description: 1 kg cheese - Price: 9.29 \u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;34monion - 1 small, finely chopped\u001b[0m\n",
      "\u001b[33mTo chop the onion finely - Description: You can use a knife and cutting board. - Price: None \u001b[0m\n",
      "\u001b[33mMake sure to remove the outer layer of the onion before chopping - Description:  - Price: None \u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;34mgarlic - 2 cloves, minced\u001b[0m\n",
      "\u001b[33mDucros Garlic & Herbs - Description: 24 g vial - Price: 2.4 \u001b[0m\n",
      "\u001b[33mBeaufort au Lait Cru AOP Reflets de France - Description: Cheese - Price: 5.95 \u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;34msalt - 1/2 teaspoon\u001b[0m\n",
      "\u001b[33mHalf-salt butter 60% mg classic - Description: 250g blister - Price: 2.09 \u001b[0m\n",
      "\u001b[33mCoffee in generous and fruity capsules extra - Description: 16 capsules of 6.2g - Price: 3.14 \u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;34mblack pepper - 1/4 teaspoon\u001b[0m\n",
      "\u001b[33mTetley Black Full-Bodied Tea - Description: The box of 25 sachets - Price: 1.1 \u001b[0m\n",
      "\u001b[33mCoffee Capsules Compatible Dolce Gusto Latte - Description: The 16 capsules of 9.7g - Price: 3.66 \u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;34mhamburger buns - 4\u001b[0m\n",
      "\u001b[33mBeef Tab - 16 pieces 150g - Description: Tool suggestion for hamburger buns - Price: 79.8 \u001b[0m\n",
      "\u001b[33mTomm of the DauphinÃ© Etoile Du Vercors - 6 cheeses 400g - Description: Tool suggestion for hamburger buns - Price: 6.51 \u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;34mcheese - 4 slices\u001b[0m\n",
      "\u001b[33mChevre Cheese in Slices - Description: 200g tray - Price: 4.0845 \u001b[0m\n",
      "\u001b[33mThe Crottin of Goat Rians - Description: Set of 4 cheeses - Price: 3.9165 \u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Thu, 14 Sep 2023 16:39:43 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '806a11502d0ef0cf-CDG', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mlettuce - 4 leaves\u001b[0m\n",
      "\u001b[33mGreen Lettuce Salad - Description: A refreshing salad made with green lettuce. - Price: 1.04 \u001b[0m\n",
      "\u001b[33mEnergy Drink Without Sugar (Red Bull) - Description: A pack of 4 cans of 25cl energy drink without sugar. - Price: 5.78 \u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;34mtomato - 4 slices\u001b[0m\n",
      "\u001b[33mCheese in Mozzarella Slices - Description: Tool for panini or pizza - Price: 3.45 \u001b[0m\n",
      "\u001b[33mBoneless Pork Ribs - Description: Tool for ribs - Price: 5.72 \u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;34mpickles - 4 slices\u001b[0m\n",
      "\u001b[33mPickles - Description: This option includes 4 slices of pickles. - Price: None \u001b[0m\n",
      "\u001b[33mWild Smoked Salmon Pacific Carrier - Description: This option includes a package of 4 slices of wild smoked salmon. - Price: 8.66 \u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;34mketchup - to taste\u001b[0m\n",
      "\u001b[33mGround Coffee Tasting Meo - Description: 2 packages of 250g - Price: 6.77 \u001b[0m\n",
      "\u001b[33mOrganic Apricots - Description: 500g tray - Price: 4.92 \u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;34mmustard - to taste\u001b[0m\n",
      "\u001b[33mGreen Pepper Mustard - Description: This is a pot of 130g - Price: 3.675 \u001b[0m\n",
      "\u001b[33mGisselbrecht White Black - CrÃ©mant d'Alsace - Description: This is a 75cl bottle - Price: 19.593 \u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;34m\n",
      "\n",
      " INSTRUCTIONS \n",
      "\u001b[0m\n",
      "\u001b[33mIn a mixing bowl, combine ground beef, onion, garlic, salt, and black pepper.\u001b[0m\n",
      "\u001b[33mShape into 4 patties.\u001b[0m\n",
      "\u001b[33mGrill or cook in a skillet over medium heat for 4-5 minutes per side, or until desired doneness.\u001b[0m\n",
      "\u001b[33mToast hamburger buns if desired.\u001b[0m\n",
      "\u001b[33mPlace cooked patties on the bottom halves of the buns.\u001b[0m\n",
      "\u001b[33mTop with cheese, lettuce, tomato, and pickles.\u001b[0m\n",
      "\u001b[33mSpread ketchup and mustard on the top halves of the buns.\u001b[0m\n",
      "\u001b[33mPlace the top halves of the buns on the assembled burgers.\u001b[0m\n",
      "\u001b[33mServe and enjoy!\u001b[0m\n",
      "\u001b[96mAsk for any recipe, start a new search, or CTRL-D to exit.\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[94mGoodbye!\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m         query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m> \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew search:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;66;03m# Run the ingredient chain to get ingredients\u001b[39;00m\n\u001b[1;32m     13\u001b[0m         result \u001b[38;5;241m=\u001b[39m generate_ingredients_chain\u001b[38;5;241m.\u001b[39mrun(query)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/ipykernel/kernelbase.py:1175\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[1;32m   1173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1174\u001b[0m     )\n\u001b[0;32m-> 1175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/ipykernel/kernelbase.py:1217\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1216\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Initialize the ingredient chain\n",
    "    generate_ingredients_chain = build_chain()\n",
    "    \n",
    "    # Print welcome messages\n",
    "    print(bcolors.OKCYAN + \"Ask for any recipe, start a new search.\" + bcolors.ENDC)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"> \").strip().lower().replace(\"new search:\", \"\")\n",
    "\n",
    "            # Run the ingredient chain to get ingredients\n",
    "            result = generate_ingredients_chain.run(query)\n",
    "            result = parser_ingredient.parse(result)\n",
    "            ingredients = result.ingredients\n",
    "\n",
    "            # Print ingredients\n",
    "            print(bcolors.OKBOLDBLUE + \"INGREDIENTS \\n\" + bcolors.ENDC)\n",
    "            print_ingredients_with_color(ingredients=ingredients)\n",
    "\n",
    "            # Build the extraction chain\n",
    "            extract_agent = build_extraction_chain()\n",
    "\n",
    "            # Print recommendations for each ingredient\n",
    "            print(bcolors.OKBOLDBLUE + \"\\n\\n RECOMMENDATIONS \\n\" + bcolors.ENDC)\n",
    "            for ingredient in ingredients:\n",
    "                sub_query = f\"{ingredient.name} - {ingredient.quantity}\"\n",
    "                response = extract_agent.run(sub_query)\n",
    "                response = parser_extraction.parse(response)\n",
    "                print_recommendations_with_color(sub_query, response)\n",
    "\n",
    "            # Print instructions\n",
    "            print(bcolors.OKBOLDBLUE + \"\\n\\n INSTRUCTIONS \\n\" + bcolors.ENDC)\n",
    "            for instruction in result.instruction:\n",
    "                print(bcolors.OKYELLOW + instruction + bcolors.ENDC)\n",
    "\n",
    "            # Print options for the next query\n",
    "            print(bcolors.OKCYAN + \"Ask for any recipe, start a new search, or CTRL-D to exit.\" + bcolors.ENDC)\n",
    "            print(bcolors.ENDC)\n",
    "            print(\">\", end=\" \", flush=True)\n",
    "\n",
    "            print(bcolors.OKBLUE + \"Goodbye!\" + bcolors.ENDC)\n",
    "        except EOFError:\n",
    "        # Exit the loop when CTRL-D (EOF) is detected\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4105f3f-ae50-4468-94dd-0f99fbba406b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b649911-ab89-456d-8748-b167fcbdd6b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain224",
   "language": "python",
   "name": "langchain224"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
