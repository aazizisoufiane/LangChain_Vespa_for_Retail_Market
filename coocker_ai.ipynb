{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b148fd3c-a0cf-4727-a4d5-7d7ba85134a4",
   "metadata": {},
   "source": [
    "# Leveraging Vespa and LLM for Enhanced Culinary and Retail Experiences: AI-Driven Recipe Search and Recommendations\n",
    "\n",
    "![Author](https://img.shields.io/badge/Author-Soufiane%20AAZIZI-brightgreen)\n",
    "[![Medium](https://img.shields.io/badge/Medium-Follow%20Me-blue)](https://medium.com/@aazizi.soufiane)\n",
    "[![GitHub](https://img.shields.io/badge/GitHub-Follow%20Me-lightgrey)](https://github.com/aazizisoufiane)\n",
    "[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect%20with%20Me-informational)](https://www.linkedin.com/in/soufiane-aazizi-phd-a502829/)\n",
    "\n",
    "---\n",
    "\n",
    "The primary objective of this notebook is to interact with a Language Model (LLM) to inquire about a recipe. The LLM will respond with the recipe's ingredients and cooking instructions. However, the key highlight is that it will generate recommendations for each ingredient from our store using Vespa.ai, a retrieval system. This means that for each ingredient, it will suggest related products or items that you might want to consider when preparing the recipe.\n",
    "\n",
    "**Example:**\n",
    "Suppose you ask the LLM for a recipe for \"Spaghetti Bolognese.\" The LLM will not only provide you with the list of ingredients and cooking instructions but also suggest products like pasta, ground beef, tomatoes, and spices that you may need to purchase for making the dish. This recommendation is based on the available products in our store, enhancing your cooking experience.\n",
    "\n",
    "### [Preprocess Data](#preprocess-data)\n",
    "### [Build and Deploy Vespa](#build-deploy-vespa)\n",
    "  - #### [Export the model to ONNX format](#export-onnx)\n",
    "  - #### [Application package](#application-package)\n",
    "### [LangChain](#LangChain)\n",
    "  - #### [Config VespaRetriever](#config-vespa-retriever)\n",
    "  - #### [Import LangChain tools](#import-lanchain-tools)\n",
    "  - #### [Function Explanation: build_chain()](#function-explanation)\n",
    "  - #### [Overall Purpose](#overall-purpose)\n",
    "  - #### [Key Components](#key-components)\n",
    "  - #### [Workflow](#workflow)\n",
    "  - #### [Recipe Recommendation and Ingredient Listing](#Recipe-Recommendation)\n",
    "  - #### [Input and Processing](#Input-and-Processing)\n",
    "  - #### [Recommendation Engine](#Recommendation-Engine)\n",
    "  - #### [Recipe Instructions](#Recipe-Instructions)\n",
    "  - #### [Interaction and Exit](#Interaction-and-Exit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "45cc3316-58c0-48ed-a272-fca8af1fdcb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d653f4e9-f3b5-4667-8041-27c5289ab515",
   "metadata": {},
   "source": [
    "# Preprocess Data <a class=\"anchor\" id=\"preprocess-data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a04457a-c475-41ed-9a5a-6846cea2c774",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b66863e-806e-4197-a7de-2de2ab264408",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "application_name = \"productsContent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f01687b-b30a-4949-a867-fd64577494cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dataframe_to_vespa_format(input_df, output_file, application_name):\n",
    "    \"\"\"\n",
    "    Convert a Pandas DataFrame to Vespa-compatible JSONL format and write it to a file.\n",
    "\n",
    "    Args:\n",
    "        input_df (pandas.DataFrame): The DataFrame to convert.\n",
    "        output_file (str): The path to the output JSONL file.\n",
    "        application_name (str): The name of the Vespa application.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Explanation:\n",
    "    This function takes a Pandas DataFrame, extracts relevant data, and converts it into Vespa-compatible JSONL format.\n",
    "    It then writes the JSONL records to a specified output file.\n",
    "\n",
    "    - input_df (pandas.DataFrame): The input DataFrame containing data to be converted.\n",
    "    - output_file (str): The path to the output JSONL file where Vespa-compatible data will be saved.\n",
    "    - application_name (str): The name of the Vespa application.\n",
    "\n",
    "    For each row in the DataFrame, the function:\n",
    "    1. Extracts the 'id', 'Price', 'title', and 'description' columns.\n",
    "    2. Constructs a JSON record in the Vespa format.\n",
    "    3. Writes the JSON record to the output JSONL file.\n",
    "\n",
    "    Note:\n",
    "    - The 'Price' column is converted to a string to maintain data consistency.\n",
    "    - The 'body' field is constructed by combining 'title', 'description', and 'Price'.\n",
    "\n",
    "    Example Usage:\n",
    "    dataframe_to_vespa_format(my_dataframe, \"output.jsonl\", \"my_vespa_app\")\n",
    "    \"\"\"\n",
    "    with open(output_file, \"w\") as jsonl_file:\n",
    "        for index, row in input_df.iterrows():\n",
    "            id_value = row[\"id\"]\n",
    "            price_value = str(row[\"Price\"])\n",
    "            body_value = (\n",
    "                \"\\nName: \"\n",
    "                + row[\"title\"]\n",
    "                + \" \\nDescription: \"\n",
    "                + row[\"description\"]\n",
    "                + \" \\nPrice: \"\n",
    "                + price_value\n",
    "            )\n",
    "            json_record = {\n",
    "                \"put\": f\"id:{application_name}:{application_name}::{id_value}\",\n",
    "                \"fields\": {\n",
    "                    \"Price\": price_value,\n",
    "                    \"title\": row[\"title\"],\n",
    "                    \"description\": row[\"description\"],\n",
    "                    \"body\": body_value,\n",
    "                },\n",
    "            }\n",
    "            jsonl_file.write(json.dumps(json_record) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5093aaa3-f5ce-4224-b3a7-a1d2cb4bd2e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "products = pd.read_csv(\"retail_product.csv\")\n",
    "dataframe_to_vespa_format(products, \"produits.jsonl\", application_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f77ce75-3793-49b0-b947-fe2fef014312",
   "metadata": {},
   "source": [
    "# Build and Deploy Vespa <a class=\"anchor\" id=\"build-deploy-vespa\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298a5bbd-c711-4a55-b92e-177a6708ad62",
   "metadata": {},
   "source": [
    "In this section, we need to build a Vespa application. Before that, we start by installing Docker locally. You can install [Docker Desktop for Mac/Windows](https://docs.docker.com/engine/install/).\n",
    "For deepdive into vespa [Vespa](https://docs.vespa.ai/en/getting-started.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18f15ce-e1a4-4efc-bf9a-436abdf85a49",
   "metadata": {},
   "source": [
    "### Export the model to ONNX format <a class=\"anchor\" id=\"export-onnx\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d60dc3-1aa4-4b7f-966c-d74e80c5dbb9",
   "metadata": {},
   "source": [
    "Vespa offers flexibility in using various embedding methods, including the [ONNX format](https://docs.vespa.ai/en/embedding.html#onnx-export), which is compatible with both the Bert embedder and the Huggingface embedder. In this case, we've chosen to use the [Huggingface embedder](https://docs.vespa.ai/en/embedding.html#huggingface-embedder) with the [all-MiniLM-L6-v2 model](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2).\n",
    "\n",
    "To set up the embedding, you can follow these steps:\n",
    "\n",
    "1. Export the ONNX model:\n",
    "\n",
    "    ```bash\n",
    "    sudo python export_model_from_hf.py --hf_model sentence-transformers/all-MiniLM-L6-v2 --output_dir all-MiniLM-L6-v2\n",
    "    ```\n",
    "\n",
    "2. Debug ONNX models using Vespa's built-in tools. Refer to the [Vespa documentation](https://docs.vespa.ai/en/embedding.html#onnx-export) for more details on this step.\n",
    "\n",
    "    ```bash\n",
    "    docker run -v `pwd`:/w \\\n",
    "      --entrypoint /opt/vespa/bin/vespa-analyze-onnx-model \\\n",
    "      vespaengine/vespa \\\n",
    "      /w/sentence-transformers-all-MiniLM-L6-v2.onnx\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee81f7da-142d-4f9b-8c19-d8054178e9d7",
   "metadata": {},
   "source": [
    "### Application package <a class=\"anchor\" id=\"application-package\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6b3bd7e-11df-4204-8777-23d0326ff154",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vespa.package import ApplicationPackage\n",
    "from vespa.package import *\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd6e2f6-82ee-48de-9f05-4ebe863060c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "Create an application package from scratch. it will create all  Vespa configuration files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "655c3827-0a13-470f-8d56-c8418324c965",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "app_package = ApplicationPackage(name=application_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78ebd50-c6fc-4068-bf2f-59c23c98e99f",
   "metadata": {},
   "source": [
    "After generating and debugging our ONNX model, we can integrate it into our Vespa application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f78007c1-1605-431b-914e-86b401ab91ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "app_package = ApplicationPackage(\n",
    "    name=application_name,\n",
    "    components=[\n",
    "        Component(\n",
    "            # id=\"e5-small-q\",\n",
    "            id=\"e5\",\n",
    "            type=\"hugging-face-embedder\",\n",
    "            parameters=[\n",
    "                Parameter(\n",
    "                    \"transformer-model\",\n",
    "                    {\n",
    "                        \"path\": \"model/all-MiniLM-L6-v2/sentence-transformers-all-MiniLM-L6-v2.onnx\"\n",
    "                    },\n",
    "                ),\n",
    "                Parameter(\n",
    "                    \"tokenizer-model\", {\"path\": \"model/all-MiniLM-L6-v2/tokenizer.json\"}\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eec2b2-09f6-46a5-ba56-33a2b7a87737",
   "metadata": {},
   "source": [
    "In our JSON file, we've defined specific keys that we will use to **populate Vespa fields** for our Vespa application. \n",
    "\n",
    "Before we embark on this journey, it's crucial to grasp the significance of the **BM25 ranking function**—an integral part of our Vespa application. \n",
    "\n",
    "**BM25** is more than just a ranking function; it's the magic wand of information retrieval. It meticulously gauges the relevance of documents to search queries by delving into factors like term frequency, inverse document frequency, and document length. \n",
    "\n",
    "\n",
    "Additionally, we employ the power of **indexing**. These indexes are the treasure maps of Vespa, created for specific fields. They're the superhighways of data retrieval, ensuring swift and efficient searches. \n",
    "\n",
    "For a deeper dive into indexing, consult the [Vespa documentation](https://docs.vespa.ai/en/reference/schema-reference.html#indexing), where you'll find the keys to unlocking even more potential.\n",
    "\n",
    "**HNSW**, short for Hierarchical Navigable Small World, is a data structure and algorithm employed in approximate nearest neighbor search. It excels at efficiently locating data points in high-dimensional spaces by constructing a hierarchical graph structure, facilitating rapid and scalable similarity searches. HNSW is commonly utilized in machine learning and data retrieval applications where the speedy identification of similar data points is essential, such as recommendation systems and image recognition.\n",
    "\n",
    "**Angular distance** is a measure of the shortest separation or difference between two points, typically in the context of spherical coordinates or geographic locations. It is commonly used to calculate the shortest path or great-circle distance between two points on the surface of a sphere, such as measuring the distance between two locations on the Earth's surface. Angular distance is typically expressed in degrees, radians, or other angular units, taking into account the curvature of the surface, and is essential in geographic applications for determining the shortest route or distance between two points on a spherical object like the Earth.\n",
    "\n",
    "**tensor**: This indicates that the tensor contains floating-point values. It's a way of specifying the data type of the elements within the tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dea4c0c7-9d47-476d-b32b-c5ffd16c516b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "app_package.schema.add_fields(\n",
    "    Field(name=\"id\", type=\"int\", indexing=[\"attribute\", \"summary\"]),\n",
    "    Field(\n",
    "        name=\"body\",\n",
    "        type=\"string\",\n",
    "        indexing=[\"index\", \"summary\"],\n",
    "        index=\"enable-bm25\",\n",
    "        bolding=True,\n",
    "    ),\n",
    "    Field(\n",
    "        name=\"title\",\n",
    "        type=\"string\",\n",
    "        indexing=[\"index\", \"summary\"],\n",
    "        index=\"enable-bm25\",\n",
    "        bolding=True,\n",
    "    ),\n",
    "    Field(\n",
    "        name=\"description\",\n",
    "        type=\"string\",\n",
    "        indexing=[\"index\", \"summary\"],\n",
    "        index=\"enable-bm25\",\n",
    "        bolding=True,\n",
    "    ),\n",
    "    Field(name=\"Price\", type=\"string\", indexing=[\"attribute\", \"summary\"]),\n",
    "    Field(\n",
    "        name=\"title_embeddings\",\n",
    "        type=\"tensor<float>(x[384])\",\n",
    "        indexing=[\"input title\", \"embed\", \"index\", \"attribute\"],\n",
    "        ann=HNSW(distance_metric=\"angular\"),\n",
    "        is_document_field=False,\n",
    "    ),\n",
    "    Field(\n",
    "        name=\"description_embeddings\",\n",
    "        type=\"tensor<float>(x[384])\",\n",
    "        indexing=[\"input description\", \"embed\", \"index\", \"attribute\"],\n",
    "        ann=HNSW(distance_metric=\"angular\"),\n",
    "        is_document_field=False,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6489a47e-9210-483c-a336-19d3e13f6c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_package.schema.add_field_set(\n",
    "    FieldSet(name=\"default\", fields=[\"title\", \"description\", \"body\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320b3c1b-3f2b-4317-a7e9-95b4c2c21bdb",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "We have defined a hybrid rank profile that takes into account both semantic search and BM25, combining them to determine the relevance of search results.\n",
    "\n",
    "**First Phase Formula**\n",
    "\n",
    "In the first phase of ranking, the formula is as follows:\n",
    "\n",
    "```markdown\n",
    "first_phase = 100 * closeness(title_embeddings) + 50 * closeness(description_embeddings) + 0.5 * bm25(body)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c6733b7a-9d7d-45bb-81db-3ef24e21d596",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "app_package.schema.add_rank_profile(\n",
    "    RankProfile(name=\"bm25\", first_phase=\"bm25(title) + 0.5 * bm25(description)\")\n",
    ")\n",
    "\n",
    "\n",
    "app_package.schema.add_rank_profile(\n",
    "    RankProfile(\n",
    "        name=\"hybrid\",\n",
    "        inputs=[(\"query(q)\", \"tensor<float>(x[384])\")],\n",
    "        inherits=\"default\",\n",
    "        first_phase=\"100*closeness(title_embeddings) + 50*closeness(description_embeddings)  + 0.5*bm25(body)\",\n",
    "        match_features=[\n",
    "            \"closeness(title_embeddings) \\\n",
    "        closeness(title_embeddings)  \\\n",
    "        bm25(body)\"\n",
    "        ],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f88f27-3cba-4f4e-82cf-b296d659a789",
   "metadata": {},
   "source": [
    "We export the application package to the disk before deployment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2c966cfd-52a7-483b-8578-8aaa62cd155b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "app_package.schema.add_document_summary(\n",
    "    DocumentSummary(\n",
    "        name=\"all\",\n",
    "        summary_fields=[\n",
    "            Summary(\"id\", \"int\"),\n",
    "            Summary(\"title\", \"string\"),\n",
    "            Summary(\"description\", \"string\"),\n",
    "            Summary(\"Price\", \"string\"),\n",
    "        ],\n",
    "    )\n",
    ")\n",
    "\n",
    "Path(\"pkg\").mkdir(parents=True, exist_ok=True)\n",
    "app_package.to_files(\"pkg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6307228-4c74-4825-bbcf-6166baff9f9b",
   "metadata": {},
   "source": [
    "Deploy `app_package` on the local machine using Docker, without leaving the notebook, by creating an instance of `VespaDocker`. You can use this command line:\n",
    "\n",
    "```python\n",
    "vespa_docker = vespa_docker.from_container_name_or_id(application_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "67c370ae-6d34-44b8-8139-133770608593",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vespa.deployment import Vespa\n",
    "\n",
    "app = Vespa(\"http://localhost:8080/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be2590ab-3477-4ced-99ff-19300a076eed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for configuration server, 0/300 seconds...\n",
      "Waiting for configuration server, 5/300 seconds...\n",
      "Waiting for application status, 0/300 seconds...\n",
      "Waiting for application status, 5/300 seconds...\n",
      "Finished deployment.\n"
     ]
    }
   ],
   "source": [
    "from vespa.deployment import VespaDocker\n",
    "\n",
    "vespa_docker = VespaDocker(port=8080)\n",
    "app = vespa_docker.deploy_from_disk(\n",
    "    application_name=application_name, application_root=\"pkg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1e2644-7f91-4958-b9c5-36dac1b0acfb",
   "metadata": {},
   "source": [
    "Now that we've deployed our Vespa application successfully, we need to install [VESPA CLI](https://docs.vespa.ai/en/vespa-cli.html) and use it to feed our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84946a9d-01aa-4e66-886f-2004813a7f2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use endpoints on localhost\n",
    "! vespa config set target local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f34e21c-89bf-4058-b7de-8fb9ff2bcc22",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"feeder.seconds\": 173.721,\n",
      "  \"feeder.ok.count\": 20262,\n",
      "  \"feeder.ok.rate\": 116.635,\n",
      "  \"feeder.error.count\": 0,\n",
      "  \"feeder.inflight.count\": 0,\n",
      "  \"http.request.count\": 20262,\n",
      "  \"http.request.bytes\": 4470241,\n",
      "  \"http.request.MBps\": 0.026,\n",
      "  \"http.exception.count\": 0,\n",
      "  \"http.response.count\": 20262,\n",
      "  \"http.response.bytes\": 2368696,\n",
      "  \"http.response.MBps\": 0.014,\n",
      "  \"http.response.error.count\": 0,\n",
      "  \"http.response.latency.millis.min\": 248,\n",
      "  \"http.response.latency.millis.avg\": 9068,\n",
      "  \"http.response.latency.millis.max\": 11715,\n",
      "  \"http.response.code.counts\": {\n",
      "    \"200\": 20262\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display a periodic summary every 3 seconds while feeding:\n",
    "! vespa  feed --progress=3 produits.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b11a19-f63e-4ba7-9763-de0c76e7dd16",
   "metadata": {},
   "source": [
    "Check the number of feeded documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7e3c6d4f-40e7-47ea-bac8-586d59a314a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20262"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.query(body={\"yql\": \"select * from sources * where true\"}).number_documents_indexed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26ab0b3-3761-4e80-845d-bf20ab5771f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "Make a simple query to test our application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "18b04a1b-6f8e-47a9-bfb9-2dc17343fc58",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'id:productsContent:productsContent::13714',\n",
       "  'relevance': 74.40122045460956,\n",
       "  'source': 'productsContent_content',\n",
       "  'fields': {'matchfeatures': {'bm25(body)': 0.0,\n",
       "    'closeness(title_embeddings)': 0.5283060204679746},\n",
       "   'sddocname': 'productsContent',\n",
       "   'description': '1.5 l can',\n",
       "   'body': '\\nName: extra organic virgin olive oil \\nDescription: 1.5 l can \\nPrice: 27.9195',\n",
       "   'title': 'extra organic virgin olive oil',\n",
       "   'documentid': 'id:productsContent:productsContent::13714',\n",
       "   'Price': '27.9195'}},\n",
       " {'id': 'id:productsContent:productsContent::2171',\n",
       "  'relevance': 66.18247444140717,\n",
       "  'source': 'productsContent_content',\n",
       "  'fields': {'matchfeatures': {'bm25(body)': 0.0,\n",
       "    'closeness(title_embeddings)': 0.43010505946507765},\n",
       "   'sddocname': 'productsContent',\n",
       "   'description': '130 g cheese',\n",
       "   'body': '\\nName: goat cheese 1/2 sec \\nDescription: 130 g cheese \\nPrice: 2.52',\n",
       "   'title': 'goat cheese 1/2 sec',\n",
       "   'documentid': 'id:productsContent:productsContent::2171',\n",
       "   'Price': '2.52'}}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword = \"olive  1 tablespoon\"\n",
    "\n",
    "result = app.query(\n",
    "    body={\n",
    "        \"yql\": \"select * from productsContent_content where userQuery() \\\n",
    "        or ({targetHits:1}nearestNeighbor(title_embeddings,q)) \\\n",
    "        or ({targetHits:1}nearestNeighbor(description_embeddings,q)) \\\n",
    "        \",\n",
    "        \"input.query(q)\": f\"embed({keyword})\",\n",
    "        \"query\": f\"{keyword}\",\n",
    "        \"ranking.profile\": \"hybrid\",\n",
    "        \"bolding\": False,\n",
    "        \"hits\": 5,\n",
    "    }\n",
    ")\n",
    "result.hits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c0ebc2-39c9-4d0e-bc37-a7b5f0f4a466",
   "metadata": {},
   "source": [
    "# LangChain <a class=\"anchor\" id=\"LangChain\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f84cfaf4-194a-4cf2-ab18-90d201045931",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.agents import AgentType\n",
    "from langchain.retrievers.vespa_retriever import VespaRetriever\n",
    "from vespa.application import Vespa\n",
    "\n",
    "# Load environment variables from the local .env file, including OPENAI_API_KEY\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "MAX_HISTORY_LENGTH = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63ab6a0-cf9f-44dc-9d31-bc60727ac1eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Config VespaRetriever <a class=\"anchor\" id=\"config-vespa-retriever\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "212e828d-0820-4aea-8b3f-92d708c41b7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "app = Vespa(url=\"http://localhost\", port=8080)\n",
    "VespaRetriever.update_forward_refs(Vespa=Vespa)  # We need this line on Jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdf8ffc-80d9-40e8-a234-c930062ba43d",
   "metadata": {},
   "source": [
    "### Import LangChain tools <a class=\"anchor\" id=\"import-lanchain-tools\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a801187-fb8d-444a-bb49-be9d3d95f4d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "from typing import Type, List, Union\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.output_parsers import PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78be833c-8c0e-4a6f-b4f9-f19ff9ff0e58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up our language model (LLM) with the specified parameters\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0613\", temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e084128-a8f0-4d12-ae2d-a9cc8765c320",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IngredientItem(BaseModel):\n",
    "    name: str\n",
    "    quantity: str\n",
    "    \n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    ingredients: List[IngredientItem]\n",
    "    instruction: List\n",
    "\n",
    "\n",
    "class Recommendation(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "    price: Union[float, None]\n",
    "    \n",
    "    @validator(\"price\", pre=True, always=True)\n",
    "    def handle_null_price(cls, value):\n",
    "        # Convert \"null\" to None or set a default value if needed\n",
    "        if value is None or value == \"null\":\n",
    "            return None  # Change \"null\" to None\n",
    "        try:\n",
    "            return float(value)\n",
    "        except (TypeError, ValueError):\n",
    "            return None  # Handle invalid values gracefully\n",
    "\n",
    "\n",
    "\n",
    "class Recs(BaseModel):\n",
    "    recommendations: List[Recommendation] = Field(description=\"List of recommendations\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6cb0dc8-0469-4019-a322-4d9fc39ad62c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKBOLDBLUE = '\\033[1;34m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    OKYELLOW = '\\033[33m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "add64fac-2d80-4817-9635-19592dda4bb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an instance of PydanticOutputParser with the 'Recs' Pydantic model\n",
    "parser_extraction = PydanticOutputParser(pydantic_object=Recs)\n",
    "\n",
    "# Create another instance of PydanticOutputParser with the 'Recipe' Pydantic model\n",
    "parser_ingredient = PydanticOutputParser(pydantic_object=Recipe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c1c893-c9e4-460b-b924-506aad57c3cb",
   "metadata": {},
   "source": [
    "## Function Explanation: build_chain() <a class=\"anchor\" id=\"function-explanation\"></a>\n",
    "\n",
    "The function `build_chain()` is responsible for constructing a processing chain designed to list the ingredients required for a recipe. Below is an explanation of the function's purpose and its inner workings:\n",
    "\n",
    "**Function Purpose:** <a class=\"anchor\" id=\"Function-Purpose\"></a>\n",
    "The primary objective of this function is to create a processing chain for culinary tasks. Specifically, it aims to provide a list of ingredients needed to prepare a given recipe. The function returns an `LLMChain` object, which represents a chain of processing steps for handling recipe-related information.\n",
    "\n",
    "**Function Details:** <a class=\"anchor\" id=\"Function-Details\"></a>\n",
    "\n",
    "- **Template Definition:** <a class=\"anchor\" id=\"Template-Definition\"></a> Inside the function, there's a multi-line string named `recipe_ingredients_template`. This string serves as a template for creating a message prompt that will be presented to the language model. It outlines the mission for the culinary expert using placeholders like `{recipe}` and `{format_instructions}`.\n",
    "\n",
    "- **Format Instructions:** The function retrieves format instructions from the `parser_ingredient` object by calling `parser_ingredient.get_format_instructions()`. These instructions are used within the message prompt template.\n",
    "\n",
    "- **Human Message Prompt Template:** The function defines a `human_message_prompt` using the `HumanMessagePromptTemplate`. It specifies the message prompt template based on `recipe_ingredients_template`. It expects an input variable named \"recipe\" and provides partial variables, including \"format_instructions.\"\n",
    "\n",
    "- **Chat Prompt Template:** A `chat_prompt_template` is created using the `ChatPromptTemplate` and is based on the `human_message_prompt`.\n",
    "\n",
    "- **LLMChain Creation:** The function then constructs an `LLMChain` named `llm_chain`. This chain utilizes a language model (`llm`) and the chat prompt template.\n",
    "\n",
    "- **Return:** Finally, the function returns the `LLMChain` object `llm_chain` as its result.\n",
    "\n",
    "In summary, this function sets up a chain of processing steps for generating precise ingredient lists for various recipes. It utilizes a language model, agent, and message prompts to encapsulate the entire information extraction process and returns the processing chain for further use in culinary-related tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14fb019e-9b7d-45f0-bb89-4aaf9892c520",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define a docstring for the function 'build_chain'\n",
    "def build_chain():\n",
    "    \"\"\"\n",
    "    Build a chain for listing ingredients of a recipe.\n",
    "\n",
    "    Returns:\n",
    "        LLMChain: A chain for processing recipe-related information.\n",
    "    \"\"\"\n",
    "    recipe_ingredients_template = \"\"\" You are a culinary expert known for your meticulous recipe analysis.\n",
    "    Your task is to list all the ingredients required for a specific recipe. \n",
    "    You have a vast knowledge of recipes from around the world and can provide precise ingredient lists for various dishes.\n",
    "\n",
    "    Here's your challenge:\n",
    "    Given the name of a recipe, list all the ingredients needed to prepare that dish. Include exact quantities and instruction.\n",
    "\n",
    "    Recipe Name: {recipe}\n",
    "\n",
    "    {format_instructions}\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve format instructions from the PydanticOutputParser\n",
    "    format_instructions = parser_ingredient.get_format_instructions()\n",
    "\n",
    "    # Define a human message prompt template\n",
    "    human_message_prompt = HumanMessagePromptTemplate(\n",
    "        prompt=PromptTemplate(\n",
    "            template=recipe_ingredients_template,\n",
    "            input_variables=[\"recipe\"],\n",
    "            partial_variables={\"format_instructions\": format_instructions},\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Create a chat prompt template\n",
    "    chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "\n",
    "    # Create an LLMChain with the language model\n",
    "    return LLMChain(llm=llm, prompt=chat_prompt_template, verbose=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0418564-5174-49c9-ae2b-665717fecc31",
   "metadata": {},
   "source": [
    "**Note**: We can consider other templates and use RouterChain by adapting our previous example. Here are some additional templates that we can add or replace with the previous one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fee5a8e-05f4-4cf5-bada-aeacca295361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "healthy_recipe_template = \"\"\"You are a health-conscious culinary expert known for crafting nutritious and delicious recipes. \n",
    "Your mission is to provide a list of ingredients and instructions for a healthy and balanced meal. Whether it's a salad, smoothie,\n",
    "or low-calorie dish, you're here to guide users toward healthier choices.\n",
    "\n",
    "Recipe Name: {3recipe}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "vegetarian_recipe_template = \"\"\"As a vegetarian culinary expert, you specialize in meat-free recipes that are both satisfying and delicious. \n",
    "Your task is to compile a list of ingredients and detailed instructions for a vegetarian dish, ensuring it's both flavorful and satisfying.\n",
    "\n",
    "Recipe Name: {recipe}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "vegan_recipe_template = \"\"\"You are a dedicated vegan chef, passionate about creating plant-based recipes. \n",
    "Your challenge is to provide a comprehensive list of ingredients and step-by-step instructions for a vegan-friendly dish. \n",
    "Your goal is to help users enjoy a cruelty-free and environmentally conscious meal.\n",
    "\n",
    "Recipe Name: {recipe}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "gluten_free_recipe_template = \"\"\"As a gluten-free cooking expert, you excel in crafting recipes suitable for individuals with gluten sensitivities or allergies. \n",
    "Your mission is to outline the ingredients and preparation steps for a gluten-free dish that is safe and delicious for those with specific dietary \n",
    "requirements.\n",
    "\n",
    "Recipe Name: {recipe}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "low_carb_recipe_template = \"\"\"You specialize in low-carb cooking, helping individuals maintain a reduced carbohydrate intake. Your task is to present a \n",
    "list of ingredients and cooking instructions for a low-carb recipe that is both satisfying and suitable for those following a low-carb lifestyle.\n",
    "\n",
    "Recipe Name: {recipe}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d343991-cd9e-44a7-9e7f-e0ca3525b15d",
   "metadata": {},
   "source": [
    "### Overall Purpose <a class=\"anchor\" id=\"overall-purpose\"></a>\n",
    "\n",
    "**Objective**: The primary purpose of the `build_extraction_chain()` function is to establish a processing chain tailored to the task of identifying the most suitable ingredients available in our store. This process aims to construct a recommendation engine that provides recommendations for each ingredient based on its availability and suitability for various recipes.\n",
    "### Key Components <a class=\"anchor\" id=\"key-components\"></a>\n",
    "\n",
    "1. **Search Function**: The notebook includes a `search` function that leverages Vespa, a search engine, to retrieve relevant product information based on user queries.\n",
    "\n",
    "2. **Ingredient Price Tool**: A custom class named `IngredientPriceTool` is defined to provide product suggestions and identify optimal options with the lowest prices based on ingredient names and quantities.\n",
    "\n",
    "3. **Agent Creation**: The `build_agent` function is responsible for creating a culinary agent, equipped with tools like the `IngredientPriceTool`, to manage culinary-related tasks.\n",
    "\n",
    "4. **Extraction Chain**: The `build_extraction_chain` function constructs an extraction chain designed for culinary tasks. It combines a language model and the culinary agent to extract various types of information, including recommendations, ingredient lists, and cooking instructions.\n",
    "\n",
    "### Workflow <a class=\"anchor\" id=\"workflow\"></a>\n",
    "\n",
    "1. Users interact with the notebook by inputting queries related to recipes and culinary tasks.\n",
    "\n",
    "2. The `search` function is employed to process user queries and retrieve relevant product information using Vespa.\n",
    "\n",
    "3. A culinary agent, created using the `build_agent` function, assists in providing ingredient suggestions and handling culinary tasks.\n",
    "\n",
    "4. The `build_extraction_chain` function manages the extraction of culinary information by utilizing the language model and culinary agent.\n",
    "\n",
    "5. Users receive responses that include ingredient lists, product recommendations, and cooking instructions based on their queries.\n",
    "\n",
    "**Note:** As we currently cannot use our [VespaRetriever](https://python.langchain.com/docs/integrations/retrievers/vespa) in its current form since it only overrides the query parameter, the temporary solution is to initialize a new retriever for every query. This will be the approach until it is fixed by the Langchain/Vespa teams. To streamline this process, we will create an agent that will handle the search operations on our behalf.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9aa1ba-7f58-4751-94b3-f9f4f15d47cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8b8b064-f82d-4988-a017-00c548dc189b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a docstring for the function 'search'\n",
    "def search(query, hits=100):\n",
    "    \"\"\"\n",
    "    Perform a search query using Vespa.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query.\n",
    "        hits (int): The number of search results to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of relevant documents.\n",
    "    \"\"\"\n",
    "    yql = {\n",
    "        \"yql\": \"select * from productsContent_content where userQuery() \\\n",
    "        or ({targetHits:1}nearestNeighbor(title_embeddings,q)) \\\n",
    "        or ({targetHits:1}nearestNeighbor(description_embeddings,q)) \\\n",
    "        \",\n",
    "        \"input.query(q)\": f\"embed({query})\",\n",
    "        \"query\": f\"{query}\",\n",
    "        \"ranking.profile\": \"hybrid\",\n",
    "        \"bolding\": False,\n",
    "        \"hits\": hits,\n",
    "    }\n",
    "\n",
    "    # Create a Vespa retriever\n",
    "    retriever = VespaRetriever(\n",
    "        app=app,\n",
    "        body=yql,\n",
    "        content_field=\"body\",\n",
    "        metadata_fields=[\"Price\"],\n",
    "        # metadata={\"body\": str},\n",
    "    )\n",
    "\n",
    "    # Get relevant documents based on the query\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "    return [d.page_content for d in docs]\n",
    "\n",
    "class IngredientInput(BaseModel):\n",
    "    \"\"\"Inputs for IngredientTool\"\"\"\n",
    "\n",
    "    ingredient_name: str = Field(description=\"Ingredient name for recipe\")\n",
    "    quantity: str = Field(description=\"quantity of ingredient for recipe\")\n",
    "\n",
    "\n",
    "class IngredientPriceTool(BaseTool):\n",
    "    name = \"IngredientTool\"\n",
    "    description = \"\"\" Please provide a list of product suggestions from the catalog based on the ingredients listed in the line. \n",
    "    Ensure that each product has the optimal quantity and the lowest price. If no exact match is found for an ingredient, please use 'MISSING'. \n",
    "    For multiple ingredients, search for the best product option for each individual ingredient.\n",
    "\n",
    "    Here is the output schema:\n",
    "    ```\n",
    "    {\"properties\": {\"ingredient\": \n",
    "        {\n",
    "            \"title\": \"Ingredient\", \"description\": \"Provide suggestions\", \"type\": \"array\", \"items\": {}}, \n",
    "            \"required\": [\"ingredient\"]\n",
    "            }\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    \"\"\"\n",
    "    # provide answer as: \"\\nProduct:   \\Quantity:    \\Instruction:\n",
    "\n",
    "    args_schema: Type[BaseModel] = IngredientInput\n",
    "\n",
    "    def _run(self, ingredient_name: str, quantity: str):\n",
    "        price_response = search(ingredient_name + quantity)\n",
    "        return price_response\n",
    "\n",
    "    def _arun(self, ticker: str):\n",
    "        raise NotImplementedError(\"search does not support async\")   \n",
    "\n",
    "def build_agent():\n",
    "    \"\"\"\n",
    "    Build a culinary agent.\n",
    "\n",
    "    Returns:\n",
    "        Agent: A culinary agent with specified tools and settings.\n",
    "    \"\"\"\n",
    "    tools = [IngredientPriceTool()]\n",
    "\n",
    "    # Initialize the agent with tools and settings\n",
    "    agent = initialize_agent(\n",
    "        tools,\n",
    "        llm,\n",
    "        agent=AgentType.OPENAI_MULTI_FUNCTIONS,\n",
    "        verbose=False,\n",
    "    )\n",
    "    return agent\n",
    "\n",
    "def build_extraction_chain():\n",
    "    \"\"\"\n",
    "    Build an extraction chain for culinary tasks.\n",
    "\n",
    "    Returns:\n",
    "        SimpleSequentialChain: A chain of processing steps for extracting culinary information.\n",
    "    \"\"\"\n",
    "    extract_ingredients_template = \"\"\"As a culinary expert tasked with extracting recommendations from the text, your mission is as follows:\n",
    "\n",
    "    Recipe Name: {text}\n",
    "\n",
    "    {format_instructions}\n",
    "    \"\"\"\n",
    "\n",
    "    # Define a human message prompt template\n",
    "    human_message_prompt = HumanMessagePromptTemplate(\n",
    "        prompt=PromptTemplate(\n",
    "            template=extract_ingredients_template,\n",
    "            input_variables=[\"text\"],\n",
    "            partial_variables={\n",
    "                \"format_instructions\": parser_extraction.get_format_instructions()\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Create a chat prompt template\n",
    "    chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "\n",
    "    # Create an extraction chain with the language model\n",
    "    extract_recs_chain = LLMChain(llm=llm, prompt=chat_prompt_template, verbose=False)\n",
    "\n",
    "    # Build the agent and create a simple sequential chain\n",
    "    _agent = build_agent()\n",
    "    ss = SimpleSequentialChain(chains=[_agent, extract_recs_chain], verbose=False)\n",
    "    return ss\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2c51262-7f91-4df6-a61b-470417879dab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_ingredients_with_color(ingredients):\n",
    "    \"\"\"\n",
    "    Print a list of ingredients with colored formatting.\n",
    "\n",
    "    Args:\n",
    "        ingredients (list): A list of ingredient objects.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    for ingredient in ingredients:\n",
    "        formatted_ingredient = f\"{bcolors.OKBLUE}{ingredient.name} - {ingredient.quantity}{bcolors.ENDC}\"\n",
    "        print(formatted_ingredient)\n",
    "\n",
    "def print_recommendations_with_color(search_query, recommendations):\n",
    "    \"\"\"\n",
    "    Print search recommendations with colored formatting.\n",
    "\n",
    "    Args:\n",
    "        search_query (str): The search query.\n",
    "        recommendations (list): A list of recommendation objects.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Print the search query in bold and blue\n",
    "    print(f\"{bcolors.OKBOLDBLUE}{search_query}{bcolors.ENDC}\")  # Bold blue text\n",
    "    \n",
    "    # Iterate through recommendations and print them in yellow\n",
    "    for recommendation in recommendations.recommendations:\n",
    "        name = recommendation.name\n",
    "        description = recommendation.description\n",
    "        price = recommendation.price\n",
    "        print(f\"{bcolors.OKYELLOW}{name} - Description: {description} - Price: {price} {bcolors.ENDC}\")  # Yellow text\n",
    "    \n",
    "    # Reset text formatting\n",
    "    print(bcolors.ENDC)  # Reset text formatting to default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349071fb-e1da-4aff-8709-93846b686d58",
   "metadata": {},
   "source": [
    "### Recipe Recommendation and Ingredient Listing <a class=\"anchor\" id=\"Recipe-Recommendation\"></a>\n",
    "\n",
    "This script is designed to provide recipe recommendations and list ingredients based on user input. It utilizes a conversational AI model and a data retrieval system to create an interactive culinary experience. Here's how it works:\n",
    "\n",
    "- The script begins by initializing a chain for generating ingredients and recommendations.\n",
    "- Users are welcomed with a message prompting them to ask for a recipe or start a new search.\n",
    "\n",
    "#### Input and Processing <a class=\"anchor\" id=\"Input-and-Processing\"></a>\n",
    "\n",
    "- Users can input a recipe request or start a new search by typing their query.\n",
    "- The script then runs the ingredient chain to retrieve a list of ingredients for the requested recipe.\n",
    "- The retrieved ingredients are displayed to the user.\n",
    "\n",
    "#### Recommendation Engine <a class=\"anchor\" id=\"Recommendation-Engine\"></a>\n",
    "\n",
    "- Next, the script builds an extraction chain to gather recommendations for each ingredient from a store.\n",
    "- It provides recommendations for available products based on the ingredients listed.\n",
    "- These recommendations are displayed to the user.\n",
    "\n",
    "#### Recipe Instructions <a class=\"anchor\" id=\"Recipe-Instructions\"></a>\n",
    "\n",
    "- In addition to ingredients and recommendations, the script also provides recipe instructions.\n",
    "- The user receives step-by-step instructions for preparing the requested dish."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f244306-cdb3-4989-b363-243f6d889340",
   "metadata": {},
   "source": [
    "#### Interaction and Exit <a class=\"anchor\" id=\"Interaction-and-Exit\"></a>\n",
    "\n",
    "- After displaying the ingredients, recommendations, and instructions, the script prompts the user for the next action.\n",
    "- Users can ask for another recipe, start a new search, or exit by using the \"CTRL-D\" shortcut (EOF).\n",
    "\n",
    "This script combines the power of conversational AI, data retrieval, and culinary expertise to enhance the user's cooking experience. It's a handy tool for finding recipes and making informed ingredient choices. Enjoy exploring new dishes and flavors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969991ff-e3b9-4589-af5f-31df809532d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96mAsk for any recipe, start a new search.\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  hamburger\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mINGREDIENTS \n",
      "\u001b[0m\n",
      "\u001b[94mGround beef - 1 pound\u001b[0m\n",
      "\u001b[94mHamburger buns - 4\u001b[0m\n",
      "\u001b[94mLettuce - 4 leaves\u001b[0m\n",
      "\u001b[94mTomato - 1\u001b[0m\n",
      "\u001b[94mOnion - 1\u001b[0m\n",
      "\u001b[94mCheese - 4 slices\u001b[0m\n",
      "\u001b[94mSalt - 1 teaspoon\u001b[0m\n",
      "\u001b[94mPepper - 1/2 teaspoon\u001b[0m\n",
      "\u001b[94mKetchup - to taste\u001b[0m\n",
      "\u001b[94mMustard - to taste\u001b[0m\n",
      "\u001b[94mPickles - to taste\u001b[0m\n",
      "\u001b[1;34m\n",
      "\n",
      " RECOMMENDATIONS \n",
      "\u001b[0m\n",
      "\u001b[1;34mGround beef - 1 pound\u001b[0m\n",
      "\u001b[33mGround beef brochettes nature socopa - Description: 4 - 400g tray - Price: 5.45 \u001b[0m\n",
      "\u001b[33mBrie good mayennay - Description: 1 kg cheese - Price: 9.29 \u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;34mHamburger buns - 4\u001b[0m\n",
      "\u001b[33mBeef Tab - Description: 16 pieces of 150g each. - Price: 79.8 \u001b[0m\n",
      "\u001b[33mTomm of the Dauphiné Etoile du Vercors - Description: 6 cheeses, 400g total. - Price: 6.51 \u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;34mLettuce - 4 leaves\u001b[0m\n",
      "\u001b[33mGreen Lettuce Salad - Description: A refreshing green lettuce salad. - Price: 1.0395 \u001b[0m\n",
      "\u001b[33mEnergy Drink without Sugar (Red Bull) - Description: A pack of 4 cans of 25cl each. - Price: 5.775 \u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;34mTomato - 1\u001b[0m\n",
      "\u001b[33mAncient Tomatoes - Description: 750g tray - Price: 6.39 \u001b[0m\n",
      "\u001b[33mInteger Chicken Simpl - Description: Chicken - Price: 6.52 \u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;34mOnion - 1\u001b[0m\n",
      "\u001b[33monions organic organic organic - Description: 1kg net - Price: 2.82 \u001b[0m\n",
      "\u001b[33mlemon carriering the market - Description: 1kg net - Price: 3.44 \u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;34mCheese - 4 slices\u001b[0m\n",
      "\u001b[33mChevre Cheese in slices - Description: 200g tray - Price: 4.0845 \u001b[0m\n",
      "\u001b[33mThe Crottin of Goat Rians - Description: The set of 4 cheeses - Price: 3.9165 \u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;34mSalt - 1 teaspoon\u001b[0m\n",
      "\u001b[33mMorille Powder - Description: The unit is 0.1kg - Price: 37.9995 \u001b[0m\n",
      "\u001b[33mSoda without Coca-Cola sugars - Description: 1L bottle - Price: 1.2705 \u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;34mPepper - 1/2 teaspoon\u001b[0m\n",
      "\u001b[33mSweet Pepper Sauce - Description: The unit of 0.25 l - Price: 8.28 \u001b[0m\n",
      "\u001b[33mDucros Ground Grey Pepper - Description: The 2 peppers of 18 g - Price: 2.78 \u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;34mKetchup - to taste\u001b[0m\n",
      "\u001b[33mGround coffee tasting meo - Description: 2 packages of 250g - Price: 6.77 \u001b[0m\n",
      "\u001b[33mOrganic apricots - Description: 500g tray - Price: 4.92 \u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;34mMustard - to taste\u001b[0m\n",
      "\u001b[33mGreen Pepper Mustard - Description: This is a pot of 130 g - Price: 3.675 \u001b[0m\n",
      "\u001b[33mGisselbrecht White Black - Crémant d'Alsace - Description: This is a 75 cl bottle - Price: 19.593 \u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;34mPickles - to taste\u001b[0m\n",
      "\u001b[33mPickled Vegetables - Description: A tangy and flavorful mix of pickled vegetables. Perfect as a side dish or topping. - Price: 5.99 \u001b[0m\n",
      "\u001b[33mPickled Eggs - Description: Hard-boiled eggs pickled in a savory brine. Great for snacking or adding to salads. - Price: 4.99 \u001b[0m\n",
      "\u001b[33mPickled Herring - Description: Marinated herring fillets with onions and spices. A traditional Scandinavian delicacy. - Price: 7.99 \u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;34m\n",
      "\n",
      " INSTRUCTIONS \n",
      "\u001b[0m\n",
      "\u001b[33mPreheat grill or stovetop grill pan over medium-high heat.\u001b[0m\n",
      "\u001b[33mIn a large bowl, combine ground beef, salt, and pepper. Mix well and form into 4 patties.\u001b[0m\n",
      "\u001b[33mPlace patties on hot grill and cook for 4-5 minutes per side, or until desired doneness.\u001b[0m\n",
      "\u001b[33mMeanwhile, prepare the toppings. Slice the onion and tomato. Wash and separate lettuce leaves.\u001b[0m\n",
      "\u001b[33mWhen patties are almost done, place cheese slices on top and allow to melt.\u001b[0m\n",
      "\u001b[33mToast the hamburger buns on the grill until lightly browned.\u001b[0m\n",
      "\u001b[33mRemove patties from grill and assemble the burgers. Place a patty on each bun, then top with lettuce, tomato, onion, ketchup, mustard, and pickles.\u001b[0m\n",
      "\u001b[33mServe immediately and enjoy!\u001b[0m\n",
      "\u001b[96mAsk for any recipe, start a new search, or CTRL-D to exit.\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[94mGoodbye!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Initialize the ingredient chain\n",
    "    generate_ingredients_chain = build_chain()\n",
    "    \n",
    "    # Print welcome messages\n",
    "    print(bcolors.OKCYAN + \"Ask for any recipe, start a new search.\" + bcolors.ENDC)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"> \").strip().lower().replace(\"new search:\", \"\")\n",
    "\n",
    "            # Run the ingredient chain to get ingredients\n",
    "            result = generate_ingredients_chain.run(query)\n",
    "            result = parser_ingredient.parse(result)\n",
    "            ingredients = result.ingredients\n",
    "\n",
    "            # Print ingredients\n",
    "            print(bcolors.OKBOLDBLUE + \"INGREDIENTS \\n\" + bcolors.ENDC)\n",
    "            print_ingredients_with_color(ingredients=ingredients)\n",
    "\n",
    "            # Build the extraction chain\n",
    "            extract_agent = build_extraction_chain()\n",
    "\n",
    "            # Print recommendations for each ingredient\n",
    "            print(bcolors.OKBOLDBLUE + \"\\n\\n RECOMMENDATIONS \\n\" + bcolors.ENDC)\n",
    "            for ingredient in ingredients:\n",
    "                sub_query = f\"{ingredient.name} - {ingredient.quantity}\"\n",
    "                response = extract_agent.run(sub_query)\n",
    "                response = parser_extraction.parse(response)\n",
    "                print_recommendations_with_color(sub_query, response)\n",
    "\n",
    "            # Print instructions\n",
    "            print(bcolors.OKBOLDBLUE + \"\\n\\n INSTRUCTIONS \\n\" + bcolors.ENDC)\n",
    "            for instruction in result.instruction:\n",
    "                print(bcolors.OKYELLOW + instruction + bcolors.ENDC)\n",
    "\n",
    "            # Print options for the next query\n",
    "            print(bcolors.OKCYAN + \"Ask for any recipe, start a new search, or CTRL-D to exit.\" + bcolors.ENDC)\n",
    "            print(bcolors.ENDC)\n",
    "            print(\">\", end=\" \", flush=True)\n",
    "\n",
    "            print(bcolors.OKBLUE + \"Goodbye!\" + bcolors.ENDC)\n",
    "        except EOFError:\n",
    "        # Exit the loop when CTRL-D (EOF) is detected\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4105f3f-ae50-4468-94dd-0f99fbba406b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b649911-ab89-456d-8748-b167fcbdd6b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain224",
   "language": "python",
   "name": "langchain224"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
